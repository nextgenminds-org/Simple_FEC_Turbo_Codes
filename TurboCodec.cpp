#include "include/TurboCodec.h"
#include <random>
#include <cmath>
#include <algorithm>
#include <stdexcept>
#include <iostream>

// Utility functions

/**
 * @brief Computes the absolute value of a number.
 * @tparam T The type of the number (e.g., int, float, double).
 * @param x The input number.
 * @return The absolute value of x.
 */
template <typename T>
constexpr T abs(T x) {
    return (x < 0) ? -x : x;
}

/**
 * @brief Generates a random interleaver (a permutation of indices).
 *        Used for scrambling input bits in turbo encoding to improve error resilience.
 * @param length The length of the interleaver.
 * @return A vector containing a permutation of indices [0, length-1].
 */
/**
 * @brief Generates a random interleaver, which is a permutation of indices.
 *        Interleavers are used in turbo coding to scramble the input bits, enhancing
 *        the robustness of the encoded data against burst errors in the channel.
 * @param length The length of the interleaver, i.e., the number of indices to permute.
 * @return A vector containing a permutation of indices [0, length - 1].
 */
std::vector<size_t> generateInterleaver(size_t length) {
    // Step 1: Create a vector of indices from 0 to length - 1.
    std::vector<size_t> indices(length);
    for (size_t i = 0; i < length; ++i)
        indices[i] = i;

    // Step 2: Use a random number generator to shuffle the indices.
    // The seed value (42) ensures that the interleaver is reproducible for testing and debugging.
    std::mt19937 generator(42); // Mersenne Twister random number generator with a fixed seed.
    std::shuffle(indices.begin(), indices.end(), generator); // Shuffle the indices randomly.

    // Step 3: Return the permuted indices as the interleaver.
    return indices;
}


/**
 * @brief Converts a string into a binary representation.
 * @param input The input string.
 * @return A vector of 0s and 1s representing the binary encoding of the string.
 */
std::vector<uint8_t> stringToBinary(const std::string& input) {
    std::vector<uint8_t> binary;
    for (char c : input) {
        for (int i = 7; i >= 0; --i) {
            binary.push_back((c >> i) & 1); // Extract each bit of the character.
        }
    }
    return binary;
}

/**
 * @brief Converts a binary representation back to a string.
 * @param binary A vector of 0s and 1s representing a binary-encoded string.
 * @return The decoded string.
 */
std::string binaryToString(const std::vector<uint8_t>& binary) {
    std::string output;
    for (size_t i = 0; i < binary.size(); i += 8) {
        char c = 0;
        for (int j = 0; j < 8; ++j) {
            c = (c << 1) | binary[i + j]; // Reconstruct the character from bits.
        }
        output += c;
    }
    return output;
}


// ConvolutionalCode class implementation

/**
 * @brief Constructor for the ConvolutionalCode class.
 * @param n The number of output bits per input bit.
 * @param m The memory size of the encoder.
 * @param gen The generator polynomials defining the code.
 */
ConvolutionalCode::ConvolutionalCode(uint32_t n, uint32_t m, const std::vector<uint32_t>& gen)
    : n(n), m(m), generators(gen), state(0) {}

/**
 * @brief Resets the internal state of the encoder to the initial state.
 */
void ConvolutionalCode::reset() {
    state = 0;
}

/**
 * @brief Computes the next state of the encoder based on the current state and input bit.
 * @param currentState The current state of the encoder.
 * @param input The input bit (0 or 1).
 * @return The next state of the encoder.
 */
uint32_t ConvolutionalCode::computeNextState(uint32_t currentState, bool input) {
    return ((currentState << 1) | input) & ((1 << m) - 1);
}

/**
 * @brief Computes the output bits generated by the encoder for a given state and input bit.
 * @param currentState The current state of the encoder.
 * @param input The input bit (0 or 1).
 * @return The output bits as an integer.
 */
uint8_t ConvolutionalCode::computeNextOutput(uint32_t currentState, bool input) {
    uint8_t output = 0;
    for (size_t i = 0; i < n; ++i) {
        uint32_t temp = currentState & generators[i];
        if (input)
            temp |= (1 << (m - 1));
        output |= (__builtin_popcount(temp) % 2) << i;
    }
    return output;
}

/**
 * @brief Decodes a sequence of received bits using the BCJR algorithm.
 *        The BCJR algorithm computes the log-likelihood ratios (LLRs) for each bit,
 *        enabling efficient decoding in turbo codes.
 * @param systematic The systematic bits received from the channel.
 * @param parity The parity bits received from the channel.
 * @param extrinsic The extrinsic information from previous iterations.
 * @param noiseVariance The variance of the noise in the channel.
 * @return A vector of log-likelihood ratios (LLRs) for the decoded bits.
 */
std::vector<double> ConvolutionalCode::decodeBCJR(const std::vector<double>& systematic,
                                                  const std::vector<double>& parity,
                                                  const std::vector<double>& extrinsic,
                                                  double noiseVariance) {
    size_t length = systematic.size(); // Number of bits in the sequence.
    size_t numStates = 1 << m; // Total number of states in the trellis (2^m, where m is the memory size).

    // Initialize alpha and beta matrices with negative infinity (logarithmic domain).
    // Alpha represents forward probabilities, and beta represents backward probabilities.
    std::vector<std::vector<double>> alpha(length + 1, std::vector<double>(numStates, -std::numeric_limits<double>::infinity()));
    std::vector<std::vector<double>> beta(length + 1, std::vector<double>(numStates, -std::numeric_limits<double>::infinity()));
    std::vector<double> llr(length, 0.0); // Log-likelihood ratios (LLRs) for the decoded bits.

    alpha[0][0] = 0.0; // Forward recursion starts with the initial state having probability 1 (log(1) = 0).
    beta[length][0] = 0.0; // Backward recursion starts with the initial state having probability 1 (log(1) = 0).

    // Forward recursion to compute alpha probabilities.
    for (size_t t = 0; t < length; ++t) {
        for (size_t state = 0; state < numStates; ++state) {
            for (bool input : {false, true}) { // Evaluate both possible inputs (0 and 1).
                size_t nextState = computeNextState(state, input); // Compute the next state for the given input.
                double gamma = (systematic[t] * (2 * input - 1) + // Contribution of systematic bits.
                                parity[t] * (2 * input - 1) +    // Contribution of parity bits.
                                extrinsic[t] * (2 * input - 1))  // Contribution of extrinsic information.
                                / noiseVariance;                // Scale by noise variance.
                // Update the alpha value for the next state.
                alpha[t + 1][nextState] = std::max(alpha[t + 1][nextState], alpha[t][state] + gamma);
            }
        }
    }

    // Backward recursion to compute beta probabilities.
    for (size_t t = length; t > 0; --t) {
        for (size_t state = 0; state < numStates; ++state) {
            for (bool input : {false, true}) { // Evaluate both possible inputs (0 and 1).
                size_t nextState = computeNextState(state, input); // Compute the next state for the given input.
                double gamma = (systematic[t - 1] * (2 * input - 1) + // Contribution of systematic bits.
                                parity[t - 1] * (2 * input - 1) +    // Contribution of parity bits.
                                extrinsic[t - 1] * (2 * input - 1))  // Contribution of extrinsic information.
                                / noiseVariance;                    // Scale by noise variance.
                // Update the beta value for the current state.
                beta[t - 1][state] = std::max(beta[t - 1][state], beta[t][nextState] + gamma);
            }
        }
    }

    // Compute LLRs (Log-Likelihood Ratios) for each bit in the sequence.
    for (size_t t = 0; t < length; ++t) {
        double prob0 = -std::numeric_limits<double>::infinity(); // Probability of bit being 0 (log domain).
        double prob1 = -std::numeric_limits<double>::infinity(); // Probability of bit being 1 (log domain).
        for (size_t state = 0; state < numStates; ++state) {
            for (bool input : {false, true}) { // Evaluate both possible inputs (0 and 1).
                size_t nextState = computeNextState(state, input); // Compute the next state for the given input.
                double gamma = (systematic[t] * (2 * input - 1) + // Contribution of systematic bits.
                                parity[t] * (2 * input - 1) +    // Contribution of parity bits.
                                extrinsic[t] * (2 * input - 1))  // Contribution of extrinsic information.
                                / noiseVariance;                // Scale by noise variance.
                // Compute the full metric for this transition.
                double metric = alpha[t][state] + gamma + beta[t + 1][nextState];
                if (!input) // If input is 0, update prob0.
                    prob0 = std::max(prob0, metric);
                else // If input is 1, update prob1.
                    prob1 = std::max(prob1, metric);
            }
        }
        llr[t] = prob1 - prob0; // Compute the LLR as the difference between log probabilities.
    }

    return llr; // Return the calculated LLRs for the entire sequence.
}

/**
 * @brief Decodes a sequence of received bits using the MAP (Maximum A Posteriori) algorithm.
 *        The MAP algorithm computes the log-likelihood ratios (LLRs) for each bit, considering
 *        the entire sequence probabilities.
 * @param systematic The systematic bits received from the channel.
 * @param parity The parity bits received from the channel.
 * @param extrinsic The extrinsic information from previous iterations.
 * @param noiseVariance The variance of the noise in the channel.
 * @return A vector of log-likelihood ratios (LLRs) for the decoded bits.
 */
std::vector<double> ConvolutionalCode::decodeMAP(const std::vector<double>& systematic,
                                                 const std::vector<double>& parity,
                                                 const std::vector<double>& extrinsic,
                                                 double noiseVariance) {
    size_t length = systematic.size(); // Number of bits in the sequence.
    size_t numStates = 1 << m; // Total number of states in the trellis (2^m, where m is the memory size).

    // Initialize alpha and beta matrices with negative infinity (logarithmic domain).
    // Alpha represents forward probabilities, and beta represents backward probabilities.
    std::vector<std::vector<double>> alpha(length + 1, std::vector<double>(numStates, -std::numeric_limits<double>::infinity()));
    std::vector<std::vector<double>> beta(length + 1, std::vector<double>(numStates, -std::numeric_limits<double>::infinity()));
    std::vector<double> llr(length, 0.0); // Log-likelihood ratios (LLRs) for the decoded bits.

    // Initialization of alpha and beta.
    alpha[0][0] = 0.0; // Forward recursion starts with the initial state having probability 1 (log(1) = 0).
    beta[length][0] = 0.0; // Backward recursion starts with the initial state having probability 1 (log(1) = 0).

    // Forward recursion to compute alpha probabilities.
    for (size_t t = 0; t < length; ++t) {
        for (size_t state = 0; state < numStates; ++state) {
            for (bool input : {false, true}) { // Evaluate both possible inputs (0 and 1).
                size_t nextState = computeNextState(state, input); // Compute the next state for the given input.
                double gamma = (systematic[t] * (2 * input - 1) + // Contribution of systematic bits.
                                parity[t] * (2 * input - 1) +    // Contribution of parity bits.
                                extrinsic[t] * (2 * input - 1))  // Contribution of extrinsic information.
                                / noiseVariance;                // Scale by noise variance.
                // Update the alpha value for the next state.
                alpha[t + 1][nextState] = std::max(alpha[t + 1][nextState], alpha[t][state] + gamma);
            }
        }
    }

    // Backward recursion to compute beta probabilities.
    for (size_t t = length; t > 0; --t) {
        for (size_t state = 0; state < numStates; ++state) {
            for (bool input : {false, true}) { // Evaluate both possible inputs (0 and 1).
                size_t nextState = computeNextState(state, input); // Compute the next state for the given input.
                double gamma = (systematic[t - 1] * (2 * input - 1) + // Contribution of systematic bits.
                                parity[t - 1] * (2 * input - 1) +    // Contribution of parity bits.
                                extrinsic[t - 1] * (2 * input - 1))  // Contribution of extrinsic information.
                                / noiseVariance;                    // Scale by noise variance.
                // Update the beta value for the current state.
                beta[t - 1][state] = std::max(beta[t - 1][state], beta[t][nextState] + gamma);
            }
        }
    }

    // Compute LLRs (Log-Likelihood Ratios) for each bit in the sequence.
    for (size_t t = 0; t < length; ++t) {
        double prob0 = -std::numeric_limits<double>::infinity(); // Probability of bit being 0 (log domain).
        double prob1 = -std::numeric_limits<double>::infinity(); // Probability of bit being 1 (log domain).
        for (size_t state = 0; state < numStates; ++state) {
            for (bool input : {false, true}) { // Evaluate both possible inputs (0 and 1).
                size_t nextState = computeNextState(state, input); // Compute the next state for the given input.
                double gamma = (systematic[t] * (2 * input - 1) + // Contribution of systematic bits.
                                parity[t] * (2 * input - 1) +    // Contribution of parity bits.
                                extrinsic[t] * (2 * input - 1))  // Contribution of extrinsic information.
                                / noiseVariance;                // Scale by noise variance.
                // Compute the full metric for this transition.
                double metric = alpha[t][state] + gamma + beta[t + 1][nextState];
                if (!input) // If input is 0, update prob0.
                    prob0 = std::max(prob0, metric);
                else // If input is 1, update prob1.
                    prob1 = std::max(prob1, metric);
            }
        }
        llr[t] = prob1 - prob0; // Compute the LLR as the difference between log probabilities.
    }

    return llr; // Return the calculated LLRs for the entire sequence.
}

/**
 * @brief Decodes a sequence of received bits using the SOVA (Soft Output Viterbi Algorithm) method.
 *        SOVA combines soft information decoding with traceback for determining the most likely path.
 * @param systematic The systematic bits received from the channel.
 * @param parity The parity bits received from the channel.
 * @param extrinsic The extrinsic information from previous iterations.
 * @param noiseVariance The variance of the noise in the channel.
 * @return A vector of log-likelihood ratios (LLRs) for the decoded bits.
 */
std::vector<double> ConvolutionalCode::decodeSOVA(const std::vector<double>& systematic,
                                                  const std::vector<double>& parity,
                                                  const std::vector<double>& extrinsic,
                                                  double noiseVariance) {
    size_t length = systematic.size(); // Number of bits in the sequence.
    size_t numStates = 1 << m; // Total number of states in the trellis (2^m, where m is the memory size).

    // Path metrics to track the likelihood of paths to each state.
    std::vector<double> pathMetrics(numStates, -std::numeric_limits<double>::infinity());
    // Decision table to store the best input bit for each state at each time step.
    std::vector<std::vector<int>> decisions(length, std::vector<int>(numStates, -1));

    pathMetrics[0] = 0.0; // Initialize the starting state with probability 1 (log(1) = 0).

    // Forward pass: Compute path metrics and decisions for each state at each time step.
    for (size_t t = 0; t < length; ++t) {
        std::vector<double> tempPathMetrics(numStates, -std::numeric_limits<double>::infinity()); // Temporary storage.

        for (size_t state = 0; state < numStates; ++state) {
            for (bool input : {false, true}) { // Evaluate both possible inputs (0 and 1).
                size_t nextState = computeNextState(state, input); // Compute the next state for the given input.
                double gamma = (systematic[t] * (2 * input - 1) + // Contribution of systematic bits.
                                parity[t] * (2 * input - 1) +    // Contribution of parity bits.
                                extrinsic[t] * (2 * input - 1))  // Contribution of extrinsic information.
                                / noiseVariance;                // Scale by noise variance.

                double metric = pathMetrics[state] + gamma; // Compute the path metric for the transition.
                if (metric > tempPathMetrics[nextState]) { // Update if this path is better.
                    tempPathMetrics[nextState] = metric;
                    decisions[t][nextState] = input; // Record the decision for the current state.
                }
            }
        }

        pathMetrics = tempPathMetrics; // Update path metrics for the next iteration.
    }

    // Traceback: Determine the most likely path through the trellis.
    std::vector<int> mostLikelyPath(length, 0); // Store the most likely input bits.
    size_t state = std::distance(pathMetrics.begin(), std::max_element(pathMetrics.begin(), pathMetrics.end())); // Start from the most likely final state.

    for (size_t t = length; t > 0; --t) {
        mostLikelyPath[t - 1] = decisions[t - 1][state]; // Record the input bit leading to the current state.
        state = computeNextState(state, mostLikelyPath[t - 1]); // Traceback to the previous state.
    }

    // Compute LLRs (Log-Likelihood Ratios) for each bit in the sequence.
    std::vector<double> llr(length, 0.0); // Store the LLRs.
    for (size_t t = 0; t < length; ++t) {
        double metric0 = -std::numeric_limits<double>::infinity(); // Metric for input bit 0.
        double metric1 = -std::numeric_limits<double>::infinity(); // Metric for input bit 1.

        for (size_t state = 0; state < numStates; ++state) {
            for (bool input : {false, true}) { // Evaluate both possible inputs (0 and 1).
                size_t nextState = computeNextState(state, input); // Compute the next state for the given input.
                double gamma = (systematic[t] * (2 * input - 1) + // Contribution of systematic bits.
                                parity[t] * (2 * input - 1) +    // Contribution of parity bits.
                                extrinsic[t] * (2 * input - 1))  // Contribution of extrinsic information.
                                / noiseVariance;                // Scale by noise variance.

                double metric = pathMetrics[state] + gamma; // Compute the metric for this transition.
                if (!input) // If input is 0, update metric0.
                    metric0 = std::max(metric0, metric);
                else // If input is 1, update metric1.
                    metric1 = std::max(metric1, metric);
            }
        }

        llr[t] = metric1 - metric0; // Compute the LLR as the difference between log probabilities.
    }

    return llr; // Return the calculated LLRs for the entire sequence.
}

/**
 * @brief Encodes a sequence of input bits using the convolutional encoder.
 * @param input A vector of input bits (0s and 1s).
 * @return A vector of pairs representing systematic and parity bits.
 */
std::vector<std::pair<uint8_t, uint8_t>> ConvolutionalCode::encode(const std::vector<uint8_t>& input) {
    std::vector<std::pair<uint8_t, uint8_t>> output;
    reset(); // Reset the internal state

    for (auto bit : input) {
        uint8_t systematicBit = bit;
        uint8_t parityBit = computeNextOutput(state, bit);
        state = computeNextState(state, bit);

        output.emplace_back(systematicBit, parityBit);
    }

    return output;
}

// TurboCodec class implementation

/**
 * @brief Constructor for the TurboCodec class.
 *        Initializes the encoders and sets default values for maxIterations and convergenceThreshold.
 */
TurboCodec::TurboCodec()
    : encoder1(2, 3, {0b1011, 0b1111}), encoder2(2, 3, {0b1011, 0b1111}), maxIterations(20), convergenceThreshold(0.001) {}

/**
 * @brief Encodes an input string into a turbo-encoded string.
 *        The Turbo Codec uses two convolutional encoders and an interleaver
 *        to create a robust encoded representation of the input.
 * @param input The input string to encode.
 * @param output The encoded output string.
 */
void TurboCodec::encode(const std::string& input, std::string& output) {
    // Step 1: Convert the input string into its binary representation.
    // Each character in the input is expanded into 8 bits (ASCII encoding).
    auto binaryInput = stringToBinary(input);

    // Step 2: Generate an interleaver for scrambling the binary input.
    // The interleaver creates a random permutation of the indices of the input bits.
    auto interleaver = generateInterleaver(binaryInput.size());

    // Step 3: Encode the binary input using the first convolutional encoder.
    // This generates systematic and parity bits for the input sequence.
    auto encoded1 = encoder1.encode(binaryInput);

    // Step 4: Apply the interleaver to the binary input.
    // The input bits are permuted according to the interleaver indices.
    std::vector<uint8_t> permutedInput(binaryInput.size());
    for (size_t i = 0; i < binaryInput.size(); ++i)
        permutedInput[interleaver[i]] = binaryInput[i];

    // Step 5: Encode the permuted input using the second convolutional encoder.
    // This generates parity bits for the permuted sequence.
    auto encoded2 = encoder2.encode(permutedInput);

    // Step 6: Construct the final output by combining the systematic and parity bits.
    // For each bit in the input sequence:
    // - Add the systematic bit from the first encoder.
    // - Add the parity bit from the first encoder.
    // - Add the parity bit from the second encoder.
    output.clear();
    for (size_t i = 0; i < binaryInput.size(); ++i) {
        output += (encoded1[i].first ? "1" : "0");   // Systematic bit from encoder1.
        output += (encoded1[i].second ? "1" : "0");  // Parity bit from encoder1.
        output += (encoded2[i].second ? "1" : "0");  // Parity bit from encoder2.
    }
}

/**
 * @brief Decodes a turbo-encoded string using the specified decoding algorithm.
 *        The decoder iteratively exchanges extrinsic information between two decoders
 *        to refine the decoded output until convergence or the maximum number of iterations is reached.
 * @param input The encoded input string (contains systematic and parity bits).
 * @param output The decoded output string.
 * @param noiseVariance The variance of the noise in the channel.
 * @param algorithm The decoding algorithm to use ("BCJR", "MAP", "SOVA", or "HYBRID").
 */
void TurboCodec::decode(const std::string& input, std::string& output, double noiseVariance, const std::string& algorithm) {
    // Step 1: Parse the input into systematic and parity bits.
    size_t length = input.size() / 3; // Each symbol contains one systematic and two parity bits.
    std::vector<double> systematic(length), parity1(length), parity2(length);

    for (size_t i = 0; i < length; ++i) {
        systematic[i] = input[i * 3] - '0';    // Extract systematic bit.
        parity1[i] = input[i * 3 + 1] - '0';  // Extract first parity bit.
        parity2[i] = input[i * 3 + 2] - '0';  // Extract second parity bit.
    }

    // Step 2: Initialize extrinsic information vectors.
    // These vectors store information exchanged between the two decoders during iterations.
    std::vector<double> extrinsic1(length, 0.0), extrinsic2(length, 0.0);

    int numIterations = 0; // Counter to track the number of decoding iterations.

    // Step 3: Iterative decoding process.
    for (numIterations = 0; numIterations < maxIterations; ++numIterations) {
        // Select the appropriate decoding algorithm for each encoder.
        if (algorithm == "BCJR") {
            extrinsic1 = encoder1.decodeBCJR(systematic, parity1, extrinsic2, noiseVariance);
            extrinsic2 = encoder2.decodeBCJR(systematic, parity2, extrinsic1, noiseVariance);
        } else if (algorithm == "MAP") {
            extrinsic1 = encoder1.decodeMAP(systematic, parity1, extrinsic2, noiseVariance);
            extrinsic2 = encoder2.decodeMAP(systematic, parity2, extrinsic1, noiseVariance);
        } else if (algorithm == "SOVA") {
            extrinsic1 = encoder1.decodeSOVA(systematic, parity1, extrinsic2, noiseVariance);
            extrinsic2 = encoder2.decodeSOVA(systematic, parity2, extrinsic1, noiseVariance);
        } else if (algorithm == "HYBRID") {
            // Use MAP for the first half of iterations, then switch to SOVA.
            if (numIterations < maxIterations / 2) {
                extrinsic1 = encoder1.decodeMAP(systematic, parity1, extrinsic2, noiseVariance);
                extrinsic2 = encoder2.decodeMAP(systematic, parity2, extrinsic1, noiseVariance);
            } else {
                extrinsic1 = encoder1.decodeSOVA(systematic, parity1, extrinsic2, noiseVariance);
                extrinsic2 = encoder2.decodeSOVA(systematic, parity2, extrinsic1, noiseVariance);
            }
        } else {
            throw std::invalid_argument("Unsupported algorithm."); // Handle invalid algorithm input.
        }

        // Step 4: Check for convergence.
        double maxDifference = 0.0; // Tracks the maximum difference between extrinsic and systematic values.
        for (size_t i = 0; i < length; ++i) {
            maxDifference = std::max(maxDifference, std::abs(extrinsic1[i] - systematic[i]));
        }

        if (maxDifference < convergenceThreshold) {
            // If the maximum difference is below the threshold, stop iterating.
            break;
        }
    }

    // Step 5: Reconstruct the message from the decoded bits.
    std::vector<uint8_t> reconstructedMessage(length);
    for (size_t i = 0; i < length; ++i) {
        // A positive systematic value indicates a bit of 1; otherwise, it's 0.
        reconstructedMessage[i] = systematic[i] > 0 ? 1 : 0;
    }

    // Step 6: Convert the reconstructed binary message back to a string.
    output = binaryToString(reconstructedMessage);

    // Step 7: Output the number of iterations performed (for debugging or display purposes).
    std::cout << "Number of iterations: " << numIterations << std::endl;
}

/**
 * @brief Sets the maximum number of decoding iterations.
 * @param iterations The maximum number of iterations.
 */
void TurboCodec::setMaxIterations(int iterations) {
    maxIterations = iterations;
}

/**
 * @brief Sets the convergence threshold for decoding.
 * @param threshold The convergence threshold.
 */
void TurboCodec::setConvergenceThreshold(double threshold) {
    convergenceThreshold = threshold;
}